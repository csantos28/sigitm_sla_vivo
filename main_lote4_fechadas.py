import asyncio
from pathlib import Path
from datetime import timedelta
import time
from typing import Optional, Tuple
import sys

# Importa√ß√£o dos m√≥dulos
from src.scraper_sigitm_async import SIGITMAutomation
from src.vpn_manager import VPNConnectionManager, VPNConfig
from src.process_data_sigitm import ExcelFileHandler
from src.connection_database import PostgreSQLHandler, PostgreSQLConfig
from src.psw import table_name
from src.syslog import SystemLogger

class MainOrchestrator:

    def __init__(self):
        self.logger = SystemLogger.configure_logger('ORQUESTRADOR')
        self.max_retries = 3
        self.retry_delay = 10
        self.vpn_config = VPNConfig()
        self.db_config = PostgreSQLConfig()

    async def _manage_vpn_connection(self) -> bool:
        """Gerencia a conex√£o VPN de forma n√£o bloqueante (async wrapper)."""

        manager = VPNConnectionManager(self.vpn_config)

        try:
            status, message = await asyncio.wait_for(
                asyncio.to_thread(manager.connect_with_fallback),
                timeout=self.vpn_config.vpn_switch_timeout + 10 # Tempo m√°ximo + margem
            )

            if status:
                self.logger.info(f"‚úÖ Conex√£o VPN/Rede estabelecida: {message}")
                return True
            else:
                self.logger.error(f"‚ùå Falha na conex√£o VPN: {message}")
        except TimeoutError:
            self.logger.critical("‚ùå Timeout atingido durante a tentativa de conex√£o VPN.")
            return False
        except Exception as e:
            self.logger.critical(f"‚ùå Erro inesperado no gerenciamento de VPN: {e}")
            return False

    async def _extract_step(self) -> Tuple[bool, Optional[Path]]:
        """Executa a extra√ß√£o (Scraper) e garante o fechamento do browser."""

        scraper = SIGITMAutomation()

        try:
            self.logger.info("üé¨ Iniciando extra√ß√£o no SIGITM...")
            return await scraper.execute_process_sigitm()
        finally:
            await scraper.close()
    
    def _load_step(self, file_path: Path) -> bool:
        """Executa Transforma√ß√£o (Pandas) e Carga (SQL)."""

        try:
            # 1. Transforma√ß√£o
            handler = ExcelFileHandler()

            # Passa como par√¢metro o file_path recebido da extra√ß√£o, eliminando a redund√¢ncia de procurar o arquivo novamente.
            result = handler.process_most_recent_file(file_path=file_path)

            if not result.success:
                self.logger.error(f"‚ùå Falha no tratamento: {result.message}")
                return False
            
            df = result.dataframe
            self.logger.info(f"‚úÖ Dados tratados com sucesso. Linhas: {len(df)}")

            # 2. Carga
            with PostgreSQLHandler(self.db_config) as db:
                self.logger.info(f"‚úÖ Conectado ao banco de dados: {self.db_config.dbname}")

                if not db.table_exists(table_name):
                    db.create_table_from_dataframe(df, table_name)
                    self.logger.info(f"üìã Tabela '{table_name}' criada com base no DataFrame.")
                
                db.bulk_insert_dataframe(df, table_name)
                self.logger.info(f"üéâ Carga de dados conclu√≠da com sucesso na tabela: {table_name}")
                
                handler.delete_most_recent_file(file_path=file_path)
                
                return True
        except Exception as e:
            self.logger.error(f"‚ùå Erro cr√≠tico na carga de dados: {e}")
            return False

    async def run_pipeline(self):
        """M√©todo principal que orquestra o loop de retentativas."""

        start_time = time.perf_counter()
    
        for attempt in range(1, self.max_retries + 1):
            self.logger.info("üî• INICIANDO PIPELINE üî•")
            self.logger.info(f"üîÅ TENTATIVA {attempt} de {self.max_retries}...")

            try:
                # Passo 0: VPN
                if not await self._manage_vpn_connection():
                    raise ConnectionError("‚ùå Falha de rede/VPN")
                
                # Passo 1: Extra√ß√£o
                success_ext, file_path = await self._extract_step()
                if not success_ext or not file_path:
                    raise RuntimeError("‚ùå Falha na extra√ß√£o dos dados")
                
                # Passo 2: Carga
                if self._load_step(file_path):
                    total_time = time.perf_counter() - start_time
                    readable_time = str(timedelta(seconds=int(total_time))).zfill(8)
                    self.logger.info(f"üî• PIPELINE CONCLU√çDO EM {readable_time}s! üî•")
                    return sys.exit(0)
            
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Falha na tentativa {attempt}: {e}")
                if attempt <= self.max_retries:
                    self.logger.info(f"‚è≥ Aguardando {self.retry_delay}s para reiniciar...")
                    await asyncio.sleep(self.retry_delay)
        
        self.logger.critical("üõë Falha definitiva ap√≥s todas as tentativas.")
        sys.exit(1)


if __name__ == "__main__":
    # Inicia o loop de eventos ass√≠ncronos do Python
    orchestrator = MainOrchestrator()
    asyncio.run(orchestrator.run_pipeline())